searchState.loadedDescShard("polars_lazy", 0, "Lazy API of Polars\nDomain specific language for the Lazy API.\nHelper to delay a failing method until the query plan is …\nLazy variant of a DataFrame.\nSpecialized expressions for <code>Series</code> of <code>DataType::Array</code>.\nCache the input at this point in the LP\nUsed by scans.\nSpecialized expressions for Categorical dtypes.\nUtility struct for the <code>when-then-otherwise</code> expression.\nUtility struct for the <code>when-then-otherwise</code> expression.\nA wrapper trait for any binary closure …\nA wrapper trait for any closure …\nThis is for <code>polars-python</code> to inject so that the …\nIn memory DataFrame\nArguments used by <code>datetime</code> in order to produce an <code>Expr</code> of …\nRemove duplicates from the table\nArguments used by <code>duration</code> in order to produce an <code>Expr</code> of …\nConfiguration variant that defaults to raising on mismatch.\nCan be used in a select statement to exclude a column from …\nExplode the aggregated list and just do a hstack instead …\nExpressions that can be used in various contexts.\nSpecialized expressions for modifying the name of existing …\nThis allows expressions to access other tables\nFilter on a boolean mask\nGroupby aggregation\nMap the group values to the position\nHorizontal concatenation of multiple plans\nAdding columns to the table without a Join\nInserts full-NULL columns for the missing ones.\nJoin the groups as ‘List&lt;group_dtype&gt;’ to the row …\nJoin operation\nSet root name as Alias\nSpecialized expressions for <code>Series</code> of <code>DataType::List</code>.\nA (User Defined) Function\nMatch / Evolve into a schema\nSpecialized expressions for Categorical dtypes.\nTake the nth column in the <code>DataFrame</code>\nExplode the aggregated list and just do a hstack instead …\nError if there are extra columns outside the target schema.\nA dimension in a reshape.\nA single source to scan from\nAn iterator for <code>ScanSources</code>\nA reference to a single item in <code>ScanSources</code>\nSet of sources to scan from\nPolars’ <code>select</code> operation, this can mean projection, but …\nExpressions in this node should only be expanding e.g. …\nOptions that apply to all sinks.\nSlice the table\nSort the table\nWrapper type that has special equality properties …\nSpecialized expressions for Struct dtypes.\nA ternary operation if true then “foo” else “bar”\nUtility struct for the <code>when-then-otherwise</code> expression.\nScan arguments shared across different scan types.\nVertical concatenation\nRepresents a user-defined function\nUtility struct for the <code>when-then-otherwise</code> expression.\nPolars flavored window functions.\nConvert all values to their absolute/positive value.\nGet the group indexes of the group by operation.\nRename Column.\nSelects all columns. Shorthand for <code>col(&quot;*&quot;)</code>.\nEvaluate whether all boolean values are true for every …\nReturns whether all values in the column are <code>true</code>.\nGet a flags value with all known bits set.\nCreate a new column with the bitwise-and of the elements …\nBitwise “and” operation.\nEvaluate whether any boolean value is true for every …\nReturns whether any of the values in the column are <code>true</code>.\nCreate a new column with the bitwise-or of the elements in …\nAppend expressions. This is done by adding the chunks of …\nApply a function/closure over the groups. This should only …\nLike <code>map_binary</code>, but used in a group_by-aggregation …\nApply a function/closure over the groups with many …\nApply a function/closure over the groups of multiple …\nGet the approximate count of unique values.\nGenerate a range of integers.\nCompute the inverse cosine of the given expression\nCompute the inverse hyperbolic cosine of the given …\nCompute the inverse sine of the given expression\nCompute the inverse hyperbolic sine of the given expression\nCompute the inverse tangent of the given expression\nCompute the inverse tangent of the given expression, with …\nCompute the inverse hyperbolic tangent of the given …\nReturn the index of the maximum value of every sublist\nGet the index value that has the maximum value.\nReturn the index of the minimal value of every sublist\nGet the index value that has the minimum value.\nGet the index values that would sort this expression.\nFind the indexes that would sort these series in order of …\nGet the first index of unique values of this expression.\nGet the indices where <code>condition</code> evaluates <code>true</code>.\nGet the <code>array::ArrayNameSpace</code>.\nTry cast the scan sources to <code>ScanSources::Paths</code>\nTake several expressions and collect them into a …\nGet the scan source at specific address\nFind the mean of all the values in the column named <code>name</code>. …\nGet the <code>binary::BinaryNameSpace</code>\nCompute <code>op(l, r)</code> (or equivalently <code>l op r</code>). <code>l</code> and <code>r</code> must …\nThe bitwise and (<code>&amp;</code>) of the bits in two flags values.\nThe bitwise and (<code>&amp;</code>) of the bits in two flags values.\nThe bitwise or (<code>|</code>) of the bits in two flags values.\nThe bitwise or (<code>|</code>) of the bits in two flags values.\nGet the underlying bits value.\nPerform an aggregation of bitwise ANDs\nEvaluate the number of set bits.\nEvaluate the number of unset bits.\nEvaluate the number most-significant set bits before …\nEvaluate the number most-significant unset bits before …\nPerform an aggregation of bitwise ORs\nEvaluate the number least-significant set bits before …\nEvaluate the number least-significant unset bits before …\nPerform an aggregation of bitwise XORs\nThe bitwise exclusive-or (<code>^</code>) of the bits in two flags …\nThe bitwise exclusive-or (<code>^</code>) of the bits in two flags …\nReturns the <code>k</code> smallest elements.\nReturns the <code>k</code> smallest rows by given column.\nuse a cache of unique, converted dates to apply the …\ncreates a logical expression with a call of the UDF\nCasts the column given by <code>Expr</code> to a different type.\nCast expression to another data type.\nCast expression to another data type.\nGet the <code>CategoricalNameSpace</code>.\nCompute the cube root of the given expression\nCeil underlying floating point array to the highest …\nClip underlying values to a set boundary.\nClip underlying values to a set boundary.\nClip underlying values to a set boundary.\nFolds the expressions from left to right keeping the first …\nCreate a Column Expression based on a column name.\nSelect multiple columns by name.\nThe bitwise negation (<code>!</code>) of the bits in a flags value, …\nCompute the schema. This requires conversion to <code>IR</code> and …\nHorizontally concatenate columns into a single array-type …\nConcat lists entries.\nHorizontally concat string columns in linear time\nCheck if the sub-array contains specific element\nCheck if the list array contain an element\nWhether all set bits in a source flags value are also set …\nCompute the cosine of the given expression\nCompute the hyperbolic cosine of the given expression\nCompute the cotangent of the given expression\nCount the values of the Series or Get counts of the group …\nCount how often the value produced by <code>element</code> occurs.\nCount how often the value produced by <code>element</code> occurs.\nCompute the covariance between two columns.\nCumulatively count values from 0 to len.\nAccumulate over multiple columns horizontally / row wise.\nGet an array with the cumulative max computed at every …\nGet an array with the cumulative min computed at every …\nGet an array with the cumulative product computed at every …\nAccumulate over multiple columns horizontally / row wise.\nGet an array with the cumulative sum computed at every …\nRun an expression over a sliding window that increases <code>1</code> …\nRun an expression over a sliding window that increases <code>1</code> …\nBin continuous values into discrete categories.\nCreate a column of date ranges from a <code>start</code> and <code>stop</code> …\nConstruct a column of <code>Datetime</code> from the provided …\nAllow casting to change time units.\nAllow datetime[ns] to be casted to any lower precision. …\nCreate a datetime range from a <code>start</code> and <code>stop</code> expression.\nCreate a column of datetime ranges from a <code>start</code> and <code>stop</code> …\nConvert from radians to degrees\nDiff every sublist.\nCalculate the n-th discrete difference between values.\nThe intersection of a source flags value with the …\nCompute the dot/inner product between two expressions.\nDrop NaN values.\nDrop null values.\nGet the <code>dt::DateLikeNameSpace</code>\nSelect multiple columns by dtype.\nSelect multiple columns by dtype.\nConstruct a column of <code>Duration</code> from the provided …\nGet a flags value with all bits unset.\nCompute the entropy as <code>-sum(pk * log(pk)</code>. where <code>pk</code> are …\nCompare <code>Expr</code> with other <code>Expr</code> on equality.\nCompare <code>Expr</code> with other <code>Expr</code> on equality where <code>None == None</code>…\nRun any <code>Expr</code> on these lists elements\nRun any <code>Expr</code> on these lists elements\nCalculate the exponentially-weighted moving average.\nCalculate the exponentially-weighted moving average by a …\nCalculate the exponentially-weighted moving standard …\nCalculate the exponentially-weighted moving variance.\nIf polars may parse matches that not contain the whole …\nExclude a column from a wildcard/regex selection.\nCalculate the exponential of all elements in the input …\nThis will update <code>scan_args.hive_options.enabled</code> to <code>true</code> if …\nReturns a column with a separate row for every array …\nExplode the String/List column.\nThe bitwise or (<code>|</code>) of the bits in each flags value.\nExtract a constant usize from an expression.\nRetrieve one of the fields of this <code>StructChunked</code> as a new …\nRetrieve one or multiple of the fields of this …\nReplace the floating point <code>NaN</code> values by a value.\nReplace the null values by a value.\nApply a filter predicate, keeping the rows that match it.\nFilter a single column.\nFirst column in a DataFrame.\nGet first item of every sublist.\nGet the first value in the group.\nTry get the first path in the scan sources\nAlias for <code>explode</code>.\nAllow Float64 -&gt; Float32\nAllow Float32 -&gt; Float64\nFloor underlying floating point array to the lowest …\nFloor divide <code>self</code> by <code>rhs</code>.\nAccumulate over multiple columns horizontally / row wise.\nFormatting string\nFormat the results of an array of expressions using a …\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nConvert from a bits value.\nConvert from a bits value exactly.\nConvert from a bits value, unsetting any unknown bits.\nThe bitwise or (<code>|</code>) of the bits in each flags value.\nGet a flags value with the bits of a flag with the given …\nThe function implementation.\nA function that cannot be expressed with <code>map</code> or <code>apply</code> and …\nFunctions\nGet items in every sublist by multiple indexes.\nTake the values by idx.\nGet items in every sub-array by index.\nGet items in every sublist by index.\nTake the values by a single index.\nGet the scan source at specific address\nCheck if <code>Expr</code> &gt; <code>Expr</code>.\nCheck if <code>Expr</code> &gt;= <code>Expr</code>.\nIndicate if this expression expands to multiple …\nCompute the hash of every element.\nGet the head of every sublist\nGet the first <code>n</code> elements of the Expr result.\nCompute the histogram of a dataset.\nTurn the <code>ScanSources</code> into some kind of identifier\nGroupBy the group to a Series.\nSelect multiple columns by index.\nFind the index of a value.\nThe bitwise or (<code>|</code>) of the bits in two flags values.\nGenerate a range of integers.\nGenerate a range of integers for each row of the input …\nAllow casting when target dtype is lossless supertype\nInterpolate intermediate values. Nulls at the beginning …\nInterpolate intermediate values. Nulls at the beginning …\nThe bitwise and (<code>&amp;</code>) of the bits in two flags values.\nWhether any set bits in a source flags value are also set …\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nTry cast the scan sources to <code>ScanSources::Paths</code> with a …\nGet a hold to an implementor of the <code>Display</code> trait that …\nWhether all known bits in this flags value are set.\nIs the first path a cloud URL?\nIndicate if this expression is a basic (non-regex) column.\nIndicate if this expression only selects columns; the …\nGet a mask of duplicated values.\nWhether all bits in this flags value are unset.\nGet mask of finite values if dtype is Float.\nGet a mask of the first unique value.\nCheck if the values of the left expression are in the …\nGet mask of infinite values if dtype is Float.\nGet a mask of the last unique value.\nIndicate if this expression represents a literal value …\nGet mask of NaN values if dtype is Float.\nGet inverse mask of NaN values if dtype is Float.\nA column which is <code>false</code> wherever <code>expr</code> is null, <code>true</code> …\nRun is_not_null operation on <code>Expr</code>.\nA column which is <code>true</code> wherever <code>expr</code> is null, <code>false</code> …\nRun is_null operation on <code>Expr</code>.\nAre the sources all paths?\nIndicate if this expression expands to multiple …\nA projection that only takes a column or a column + alias.\nGet a mask of unique values.\nYield a set of contained flags values.\nYield a set of contained named flags values.\nJoin all string items in a sub-array and place a separator …\nJoin all string items in a sublist and place a separator …\nKeep the original root name\nWhich rows to keep.\nCompute the kurtosis (Fisher or Pearson).\nLast column in a DataFrame.\nGet last item of every sublist.\nGet the last value in the group.\nReturn the number of rows in the context.\nReturn the number of elements in each list.\nGenerate a series of equally-spaced points.\nCreate a column of linearly-spaced sequences from ‘start…\nGet the <code>list::ListNameSpace</code>\nCreate a Literal Expression from <code>L</code>. A literal expression …\nCompute the logarithm to a given base.\nCompute the natural logarithm of all elements plus one in …\nLogical “and” operation.\nLogical “or” operation.\nGet minimal value that could be hold by this dtype.\nCheck if <code>Expr</code> &lt; <code>Expr</code>.\nCheck if <code>Expr</code> &lt;= <code>Expr</code>.\nThe output file needs to maintain order of the data that …\nThis will maintain the order of the input. Note that this …\nDefine an alias by mapping a function over the original …\nApply a function/closure once the logical plan get …\nApply a closure on the two columns that are evaluated from …\nSet the timezone of a datetime dtype.\nMap a single dtype.\nApply a function/closure once the logical plan get …\nApply a function/closure over multiple columns once the …\nMap to a float supertype if numeric, else preserve\nMap to a float supertype.\nMap the dtype to the dtype of the list/array elements.\nMap the dtypes to the “supertype” of a list of lists.\nMap the dtype to the “supertype” of all fields.\nFind the maximum of all the values in the column named <code>name</code>…\nCompute the maximum of the items in every subarray.\nCompute the maximum of the items in every sublist.\nReduce groups to maximum value.\nCreate a new column with the maximum value per row.\nFind the mean of all the values in the column named <code>name</code>. …\nCompute the mean of every sublist and return a <code>Series</code> of …\nReduce groups to the mean value.\nCompute the mean of all values horizontally across columns.\nFind the median of all the values in the column named <code>name</code>…\nCompute the median of the items in every subarray.\nReduce groups to the median value.\nGet the <code>meta::MetaNameSpace</code>\nFind the minimum of all the values in the column named <code>name</code>…\nCompute the minimum of the items in every subarray.\nCompute the minimum of the items in every sublist.\nReduce groups to minimal value.\nCreate a new column with the minimum value per row.\nRecursively create all the directories in the path.\nCompute the mode(s) of this column. This is the most …\nGet the number of unique values in the groups.\nGet the <code>name::ExprNameNameSpace</code>\nname\nReduce groups to maximum value.\nReduce groups to minimal value.\nCompare <code>Expr</code> with other <code>Expr</code> on non-equality.\nCompare <code>Expr</code> with other <code>Expr</code> on non-equality where …\nConstruct a new <code>DatetimeArgs</code> set to <code>year</code>, <code>month</code>, <code>day</code>\nCreate a new <code>DurationArgs</code> with all fields set to <code>lit(0)</code>. …\nCreate a new UserDefinedFunction\nNegates a boolean column.\nNegate <code>Expr</code>.\nThe bitwise negation (<code>!</code>) of the bits in a flags value, …\nNth column in a DataFrame.\nGet the null count of the column/group.\nOptions for the function.\nBitwise “or” operation.\nDefine a default for the <code>when-then-otherwise</code> expression.\nDefine a default for the <code>when-then-otherwise</code> expression.\nGet the output name of this expression.\nApply window function over a subgroup. This is similar to …\nComputes percentage change between values.\nCompute the pearson correlation between two columns.\nConstant Pi\nPop latest expression and return the input(s) of the …\nRaise expression to the power <code>exponent</code>\nSlice applied before predicates\nallow predicate pushdown optimizations\nAdd a prefix to the root column name.\nGet the product aggregation of an expression.\nallow projection pushdown optimizations\nBin continuous values into discrete categories based on …\nBin continuous values into discrete categories using …\nFind a specific quantile of all the values in the column …\nCompute the quantile per group.\nConvert from degrees to radians\nAssign ranks to data, dealing with ties appropriately.\nAnalogous to <code>Iterator::reduce</code>.\nRemove rows matching a filter predicate (note that rows …\nThe intersection of a source flags value with the …\nRename the fields of the <code>StructChunked</code>.\nCreate a column of length <code>n</code> containing <code>n</code> copies of the …\nRepeat the column <code>n</code> times, where <code>n</code> is determined by the …\nReplace the given values with other values.\nReplace the given values with other values.\nThe function output type.\nReverse every sublist\nReverse column\nGet the lengths of runs of identical values.\nSimilar to <code>rle</code>, but maps values to run IDs.\nApply a rolling skew.\nApply a custom function over a rolling/ moving window of …\nApply a custom function over a rolling/ moving window of …\nApply a rolling maximum.\nApply a rolling maximum based on another column.\nApply a rolling mean.\nApply a rolling mean based on another column.\nApply a rolling median.\nApply a rolling median based on another column.\nApply a rolling minimum.\nApply a rolling minimum based on another column.\nApply a rolling quantile.\nApply a rolling quantile based on another column.\nApply a rolling skew.\nApply a rolling std-dev.\nApply a rolling std-dev based on another column.\nApply a rolling sum.\nApply a rolling sum based on another column.\nApply a rolling variance.\nApply a rolling variance based on another column.\nGet the root column names.\nRound underlying floating point array to given decimal …\nRound to a number of significant figures.\nProxy of the number of rows in both sides of the joins …\nUser-provided schema of the file. Will be inferred during …\nFind indices where elements should be inserted to maintain …\nCall <code>insert</code> when <code>value</code> is <code>true</code> or <code>remove</code> when <code>value</code> is …\nReturn the SET DIFFERENCE between both list arrays.\nReturn the SET INTERSECTION between both list arrays.\nSet this <code>Series</code> as <code>sorted</code> so that downstream code can use …\nReturn the SET SYMMETRIC DIFFERENCE between both list …\nShift every sub-array.\nShift every sublist.\nShift the values in the array by some period. See the …\nShift the values in the array by some period and fill the …\nReturns\nShrink numeric columns to the minimal required datatype …\nCompute the sign of the given expression\nCompute the sine of the given expression\nCompute the hyperbolic sine of the given expression\nCompute the sample skewness of a data set.\nSlice every sublist.\nSlice the Series. <code>offset</code> may be negative.\nTake only a slice of the result\nSort every sublist.\nSort with given options.\nSort this column by the ordering of another column …\nCompute the spearman rank correlation between two columns. …\nCompute the square root of the given expression\nCompute the std of the items in every subarray.\nStandard deviation of the values of the Series.\nGet the <code>string::StringNameSpace</code>\nIf set then polars will return an error if any date …\nCast expression to another data type. Throws an error if …\nGet the <code>struct_::StructNameSpace</code>.\nThe intersection of a source flags value with the …\nThe intersection of a source flags value with the …\nSubset of columns that will be taken into account.\nAdd a suffix to the root column name.\nSum all the values in the column named <code>name</code>. Shorthand for …\nCompute the sum of the items in every subarray.\nCompute the sum the items in every sublist.\nReduce groups to the sum of all the values.\nSum all values horizontally across columns.\nThe bitwise exclusive-or (<code>^</code>) of the bits in two flags …\nCall sync when closing the file.\nGet the tail of every sublist\nGet the last <code>n</code> elements of the Expr result.\nCompute the tangent of the given expression\nCompute the hyperbolic tangent of the given expression\nAdd a condition to the <code>when-then-otherwise</code> expression.\nCreate a column of time ranges from a <code>start</code> and <code>stop</code> …\nConvert a List column into an Array column with the same …\nGet Field result of the expression. The schema is the …\nGet the name for <code>include_paths</code>\nCast the Array column to List column with the same inner …\nUpdate the root column name to use lowercase characters.\nTurn the scan source into a memory slice\nMap to a physical type.\nConvert this <code>List</code> to a <code>Series</code> of type <code>Struct</code>. The width …\nUpdate the root column name to use uppercase characters.\nThe bitwise exclusive-or (<code>^</code>) of the bits in two flags …\nReturns the <code>k</code> largest elements.\nReturns the <code>k</code> largest rows by given column.\nMap a single dtype with a potentially failing mapper …\nMap all dtypes with a potentially failing mapper function.\nMap a single field with a potentially failing mapper …\nMap the dtype to the dtype of the array elements, with …\nUndo any renaming operation like <code>alias</code>, <code>keep_name</code>.\nReturn the SET UNION between both list arrays.\nThe bitwise or (<code>|</code>) of the bits in two flags values.\nKeep only the unique values in every sub-array.\nKeep only the unique values in every sublist.\nGet unique values of this expression.\nReturns a count of the unique values in the order of …\nKeep only the unique values in every sub-array.\nKeep only the unique values in every sublist.\nGet unique values of this expression, while maintaining …\nGet maximal value that could be hold by this dtype.\nCount all unique values and create a struct mapping value …\nCompute the var of the items in every subarray.\nVariance of the values of the Series.\nStart a <code>when-then-otherwise</code> expression.\nAttach a statement to the corresponding condition.\nAdd another condition to the <code>when-then-otherwise</code> …\nSet the day\nSet the days\nSet a dtype.\nSet <code>milliseconds</code>, <code>microseconds</code>, and <code>nanoseconds</code>\nSet <code>hour</code>, <code>minute</code>, and <code>second</code>\nSet <code>hours</code>, <code>minutes</code>, and <code>seconds</code>\nSet the hour\nSet the hours\nSet the microsecond\nSet the microseconds\nSet the milliseconds\nSet the minute\nSet the minutes\nSet the month\nSet the nanoseconds\nField with the same dtype.\nSet the second\nSet the seconds\nSet the weeks\nSet the year\nBitwise “xor” operation.\nLocal use cases often repeatedly collect the same <code>LazyFrame</code>…\nMaterialized at IR except for AnonymousScan.\nThe schema to match to.\nfunction to apply\nAlso has the input. i.e. avg(“foo”)\nfunction to apply\nfunction arguments\nfunction arguments\nlength is not yet known so we accept negative offsets\noutput dtype of the function\nSpecialized expressions for <code>Series</code> of <code>DataType::String</code>.\nCheck if a binary value contains a literal binary.\nCheck if a binary value ends with the given sequence.\nReturns the argument unchanged.\nCalls <code>U::from(self)</code>.\nReturn the size (number of bytes) in each element.\nCheck if a binary value starts with the given sequence.\nSpecialized expressions for Categorical dtypes.\nSpecialized expressions for <code>Series</code> with dates/datetimes.\nAdd a given number of business days.\nGet the base offset from UTC.\nChange the underlying <code>TimeUnit</code>. And update the data …\nGet the century of a Date/Datetime\nCombine an existing Date/Datetime with a Time, creating a …\nChange the underlying <code>TimeZone</code> of the <code>Series</code>. This does …\nGet the (local) date of a Date/Datetime.\nGet the (local) datetime of a Datetime.\nGet the month of a Date/Datetime.\nGet the additional offset from UTC currently in effect …\nReturns the argument unchanged.\nGet the hour of a Datetime/Time64.\nCalls <code>U::from(self)</code>.\nDetermine whether days are business days.\nGet the iso-year of a Date/Datetime. This may not …\nGet the microsecond of a Time64 (scaled from nanosecs).\nGet the millennium of a Date/Datetime\nGet the millisecond of a Time64 (scaled from nanosecs).\nGet the minute of a Datetime/Time64.\nGet the month of a Date/Datetime.\nRoll forward to the last day of the month.\nRoll backward to the first day of the month.\nGet the nanosecond part of a Time64.\nOffset this <code>Date/Datetime</code> by a given offset <code>Duration</code>. This …\nGet the ordinal_day of a Date/Datetime.\nExtract quarter from underlying NaiveDateTime …\nReplace the time units of a value\nRound the Datetime/Date range into buckets.\nGet the second of a Datetime/Time64.\nConvert from Date/Time/Datetime into String with the given …\nGet the (local) time of a Date/Datetime/Time.\nReturn the timestamp (UNIX epoch) of a Datetime/Date.\nConvert from Date/Time/Datetime into String with the given …\nExpress a Duration in terms of its total number of integer …\nExpress a Duration in terms of its total number of integer …\nExpress a Duration in terms of its total number of …\nExpress a Duration in terms of its total number of …\nExpress a Duration in terms of its total number of integer …\nExpress a Duration in terms of its total number of …\nExpress a Duration in terms of its total number of integer …\nTruncate the Datetime/Date range into buckets.\nExtract the week from the underlying Date representation. …\nExtract the ISO week day from the underlying Date …\nChange the underlying <code>TimeUnit</code> of the <code>Series</code>. This does …\nGet the year of a Date/Datetime\nA dimension in a reshape.\nReturns the argument unchanged.\nCalls <code>U::from(self)</code>.\nReturns the argument unchanged.\nCalls <code>U::from(self)</code>.\nArguments used by <code>datetime</code> in order to produce an <code>Expr</code> of …\nArguments used by <code>duration</code> in order to produce an <code>Expr</code> of …\nSelects all columns. Shorthand for <code>col(&quot;*&quot;)</code>.\nCreate a new column with the bitwise-and of the elements …\nCreate a new column with the bitwise-or of the elements in …\nLike <code>map_binary</code>, but used in a group_by-aggregation …\nGenerate a range of integers.\nFind the indexes that would sort these series in order of …\nGet the indices where <code>condition</code> evaluates <code>true</code>.\nTake several expressions and collect them into a …\nFind the mean of all the values in the column named <code>name</code>. …\nCasts the column given by <code>Expr</code> to a different type.\nFolds the expressions from left to right keeping the first …\nCreate a Column Expression based on a column name.\nCollect all <code>LazyFrame</code> computations.\nSelect multiple columns by name.\nConcat multiple <code>LazyFrame</code>s vertically.\nHorizontally concatenate columns into a single array-type …\nConcat LazyFrames diagonally. Calls <code>concat</code> internally.\nConcat LazyFrames horizontally.\nConcat lists entries.\nHorizontally concat string columns in linear time\nCompute the covariance between two columns.\nAccumulate over multiple columns horizontally / row wise.\nAccumulate over multiple columns horizontally / row wise.\nCreate a date range from a <code>start</code> and <code>stop</code> expression.\nCreate a column of date ranges from a <code>start</code> and <code>stop</code> …\nConstruct a column of <code>Datetime</code> from the provided …\nCreate a datetime range from a <code>start</code> and <code>stop</code> expression.\nCreate a column of datetime ranges from a <code>start</code> and <code>stop</code> …\nSelect multiple columns by dtype.\nSelect multiple columns by dtype.\nConstruct a column of <code>Duration</code> from the provided …\nAccumulate over multiple columns horizontally / row wise.\nFormat the results of an array of expressions using a …\nSelect multiple columns by index.\nGenerate a range of integers.\nGenerate a range of integers for each row of the input …\nA column which is <code>false</code> wherever <code>expr</code> is null, <code>true</code> …\nA column which is <code>true</code> wherever <code>expr</code> is null, <code>false</code> …\nGenerate a series of equally-spaced points.\nCreate a column of linearly-spaced sequences from ‘start…\nApply a closure on the two columns that are evaluated from …\nFind the maximum of all the values in the column named <code>name</code>…\nFind the mean of all the values in the column named <code>name</code>. …\nFind the median of all the values in the column named <code>name</code>…\nFind the minimum of all the values in the column named <code>name</code>…\nNegates a boolean column.\nCompute the pearson correlation between two columns.\nFind a specific quantile of all the values in the column …\nAnalogous to <code>Iterator::reduce</code>.\nCreate a column of length <code>n</code> containing <code>n</code> copies of the …\nCompute the spearman rank correlation between two columns. …\nSum all the values in the column named <code>name</code>. Shorthand for …\nGenerate a time range.\nCreate a column of time ranges from a <code>start</code> and <code>stop</code> …\nThis is for <code>polars-python</code> to inject so that the …\nCurrently intended only for Iceberg support\nReturns the argument unchanged.\nCalls <code>U::from(self)</code>.\n[minor, micro]\nSerializable version of <code>GetOutput</code> for Python UDFs.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nA function that returns a Python Generator. The generator …\nEither the schema fn or schema is set.\nSpecialized expressions for <code>Series</code> of <code>DataType::String</code>.\nCheck if this column of strings contains a Regex. If <code>strict</code>…\nCheck if a string value contains a literal substring.\nCount all successive non-overlapping regex matches.\nCheck if a string value ends with the <code>sub</code> string.\nExtract a regex pattern from the a string value. If …\nExtract each successive non-overlapping match in an …\nFind the index of a substring defined by a regular …\nFind the index of a literal substring within another …\nReturns the argument unchanged.\nTake the first <code>n</code> characters of the string values.\nCalls <code>U::from(self)</code>.\nConcat the values into a string array.\nReturn the length of each string as the number of bytes.\nReturn the length of each string as the number of …\nNormalize each string\nPad the end of the string until it reaches the given …\nPad the start of the string until it reaches the given …\nReplace values that match a regex <code>pat</code> with a <code>value</code>.\nReplace all values that match a regex <code>pat</code> with a <code>value</code>.\nReplace values that match a regex <code>pat</code> with a <code>value</code>.\nReverse each string\nSlice the string values.\nSplit the string by a substring. The resulting dtype is …\nSplit exactly <code>n</code> times by a given substring. The resulting …\nSplit exactly <code>n</code> times by a given substring and keep the …\nSplit the string by a substring and keep the substring. …\nSplit by a given substring, returning exactly <code>n</code> items. If …\nCheck if a string value starts with the <code>sub</code> string.\nRemove leading and trailing characters, or whitespace if …\nRemove trailing characters, or whitespace if matches is …\nRemove leading characters, or whitespace if matches is …\nRemove prefix.\nRemove suffix.\nConvert a String column into a Date/Datetime/Time column.\nTake the last <code>n</code> characters of the string values.\nConvert a String column into a Date column.\nConvert a String column into a Datetime column.\nConvert a String column into a Decimal column.\nParse string in base radix into decimal.\nConvert all characters to lowercase.\nConvert a String column into a Time column.\nConvert all characters to titlecase.\nConvert all characters to uppercase.\nPad the start of the string with zeros until it reaches …\nRepresents a user-defined function\nThe function implementation.\nname\nOptions for the function.\nThe function output type.\nAllowedOptimizations\nCheck if operations are order dependent and unset …\nCluster sequential <code>with_columns</code> calls to independent calls.\nCollapse slower joins with filters into faster joins.\nRun common-subexpression-elimination. This elides …\nRun common-subplan-elimination. This elides duplicate …\nRun every node eagerly. This turns off multi-node …\nReplace simple projections with a faster inlined …\nReads LazyFrame from a filesystem or a cloud storage. …\nLazy abstraction over an eager <code>DataFrame</code>.\nUtility struct for lazy group_by operation.\nAllowed optimizations.\nApply predicates/filters as early as possible.\nOnly read columns that are used later in the query.\nTry to estimate the number of rows so that joins can …\nRun many expression optimization rules until fixed point.\nPushdown slices/limits.\nRun nodes that are capably of doing so on the streaming …\nDo type checking of the IR.\nRun many type coercion optimization rules until fixed …\nRun every node eagerly. This turns off multi-node …\nGroup by and aggregate.\nGet a flags value with all known bits set.\nAllow parallel table evaluation.\nLeft anti join this query with another lazy query.\nApply a function over the groups as a new DataFrame.\nThe bitwise and (<code>&amp;</code>) of the bits in two flags values.\nThe bitwise and (<code>&amp;</code>) of the bits in two flags values.\nThe bitwise or (<code>|</code>) of the bits in two flags values.\nThe bitwise or (<code>|</code>) of the bits in two flags values.\nGet the underlying bits value.\nThe bitwise exclusive-or (<code>^</code>) of the bits in two flags …\nThe bitwise exclusive-or (<code>^</code>) of the bits in two flags …\nCaches the result into a new LazyFrame.\nCancel the query at earliest convenience.\nCast named frame columns, resulting in a new LazyFrame …\nCast all frame columns to the given dtype, resulting in a …\nCloudOptions used to list files.\nCloudOptions used to list files.\nCloudOptions used to list files.\nCloudOptions used to list files.\nWhether to coalesce join columns.\nExecute all the lazy operations and collect them into a …\nGet a handle to the schema — a map from column names to …\nExecute all the lazy operations and collect them into a …\nThe bitwise negation (<code>!</code>) of the bits in a flags value, …\nRecommended concatenation of LazyFrames from many input …\nRecommended concatenation of LazyFrames from many input …\nWhether all set bits in a source flags value are also set …\nReturn the number of non-null elements for each column.\nCreates the Cartesian product from both frames, preserving …\nReturn a String describing the optimized logical plan.\nReturn a String describing the optimized logical plan in …\nReturn a String describing the naive (un-optimized) …\nReturn a String describing the naive (un-optimized) …\nThe intersection of a source flags value with the …\nRemoves columns from the DataFrame. Note that it’s …\nDrop rows containing one or more NaN values.\nRemoves columns from the DataFrame. Note that it’s …\nDrop rows containing one or more None values.\nGet a flags value with all bits unset.\nReturn a String describing the logical plan.\nApply explode operation. See eager explode.\nThe bitwise or (<code>|</code>) of the bits in each flags value.\nFetch the result.\nFetch is like a collect operation, but it overwrites the …\nAwait the result synchronously.\nFill NaN values in the DataFrame with an expression.\nFill None values in the DataFrame with an expression.\nFilter frame rows that match a predicate expression.\nFinish builder\nGet the final LazyFrame.\nGet the final LazyFrame.\nGet the final LazyFrame.\nGet the final LazyFrame. This method assumes, that path is …\nGet the first row.\nForce parallel table evaluation.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nConvert from a bits value.\nConvert from a bits value exactly.\nConvert from a bits value, unsetting any unknown bits.\nThe bitwise or (<code>|</code>) of the bits in each flags value.\nGet a flags value with the bits of a flag with the given …\nFull outer join this query with another lazy query.\nGet current optimizations.\nExpand path given via globbing rules.\nPerforms a “group-by” on a <code>LazyFrame</code>, producing a …\nGroup based on a time value (or index value of type Int32, …\nSimilar to <code>group_by</code>, but order of the DataFrame is …\nReturn first n rows of each group\nSelect the join type.\nInner join this query with another lazy query.\nThe bitwise or (<code>|</code>) of the bits in two flags values.\nThe bitwise and (<code>&amp;</code>) of the bits in two flags values.\nWhether any set bits in a source flags value are also set …\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nWhether all known bits in this flags value are set.\nWhether all bits in this flags value are unset.\nYield a set of contained flags values.\nYield a set of contained named flags values.\nGeneric function to join two LazyFrames.\nConsume <code>self</code> and return a <code>JoinBuilder</code> to customize a join …\nJoin on null values. By default null values will never …\nGet the last row.\nLeft outer join this query with another lazy query.\nThe expressions you want to join the left table on.\nLimit the DataFrame to the first <code>n</code> rows.\nReduce memory usage at the expense of performance\nWhether to preserve the row order.\nApply a function/closure once the logical plan get …\nRe-export to shorten code.\nMatch or evolve to a certain schema.\nAggregate all the columns as their maximum values.\nAggregate all the columns as their mean values.\nAggregate all the columns as their median values.\nAggregate all the columns as their minimum values.\nTry to stop parsing when <code>n</code> rows are parsed. During …\nTry to stop parsing when <code>n</code> rows are parsed. During …\nTry to stop parsing when <code>n</code> rows are parsed. During …\nCreate the <code>JoinBuilder</code> with the provided <code>LazyFrame</code> as the …\nThe bitwise negation (<code>!</code>) of the bits in a flags value, …\nAggregate all the columns as the sum of their null value …\nThe expressions you want to join both tables on.\nModule containing implementation of the pivot operation.\nProfile a LazyFrame.\nAggregate all the columns as their quantile values.\nRechunk the memory to contiguous chunks when parsing is …\nRemove frame rows that match a predicate expression.\nThe intersection of a source flags value with the …\nRename columns in the DataFrame.\nReverse the <code>DataFrame</code> from top to bottom.\nThe expressions you want to join the right table on.\nCreate rolling groups based on a time column.\nAdd a row index column.\nReturn the row index settings.\nAdd a row index column.\nCreate a LazyFrame directly from a ipc scan.\nCreate a LazyFrame directly from a parquet scan.\nCreate a LazyFrame directly from a parquet scan.\nCreate a LazyFrame directly from a parquet scan.\nSelect (and optionally rename, with <code>alias</code>) columns from …\nLeft semi join this query with another lazy query.\nCall <code>insert</code> when <code>value</code> is <code>true</code> or <code>remove</code> when <code>value</code> is …\nShift the values by a given period and fill the parts that …\nShift the values by a given period and fill the parts that …\nStream a query result into an csv file. This is useful if …\nStream a query result into an csv file in a partitioned …\nStream a query result into an ipc/arrow file. This is …\nStream a query result into an ipc/arrow file in a …\nStream a query result into a JSON file. This is useful if …\nStream a query result into a JSON file in a partitioned …\nStream a query result into a parquet file. This is useful …\nStream a query result into a parquet file in a partitioned …\nSlice the DataFrame using an offset (starting row) and a …\nAdd a sort operation to the logical plan.\nAdd a sort operation to the logical plan.\nGet the sources for this reader.\nAggregate all the columns as their standard deviation …\nThe intersection of a source flags value with the …\nThe intersection of a source flags value with the …\nSuffix to add duplicate column names in join. Defaults to …\nAggregate all the columns as their sum values.\nThe bitwise exclusive-or (<code>^</code>) of the bits in two flags …\nGet the last <code>n</code> rows.\nReturn last n rows of each group\nGet a dot language representation of the LogicalPlan.\nGet a dot language representation of the streaming …\nThe bitwise exclusive-or (<code>^</code>) of the bits in two flags …\nThe bitwise or (<code>|</code>) of the bits in two flags values.\nDrop non-unique rows without maintaining the order of kept …\nDrop non-unique rows and maintain the order of kept rows.\nUnnest the given <code>Struct</code> columns: the fields of the <code>Struct</code> …\nUnpivot the DataFrame from wide to long format.\nAggregate all the columns as their variance values.\nThe right table in the join.\nCache the DataFrame after reading.\nCheck if operations are order dependent and unset …\nSets the chunk size used by the parser. This influences …\nToggle cluster with columns optimization.\nToggle collapse joins optimization.\nAdd or replace a column, given as an expression, to a …\nAdd or replace multiple columns, given as expressions, to …\nAdd or replace multiple columns to a DataFrame, but …\nToggle common subexpression elimination optimization on or …\nToggle common subplan elimination optimization on or off\nSet the comment prefix for this instance. Lines starting …\nOverwrite the schema with the dtypes in this given Schema. …\nSet  <code>CsvEncoding</code>\nSet the <code>char</code> used as end of line. The default is <code>b&#39;\\n&#39;</code>.\nExpand path given via globbing rules.\nSet whether the CSV file has headers\nContinue with next batch when a ParserError is encountered.\nSet values as <code>Null</code> if parsing fails because of schema …\nSet the number of rows to use when inferring the csv …\nSet the number of rows to use when inferring the json …\nReduce memory usage at the expense of performance\nTreat missing fields as null.\nConfigure the row limit.\nTry to stop parsing when <code>n</code> rows are parsed. During …\nTry to stop parsing when <code>n</code> rows are parsed. During …\nSet values that will be interpreted as missing/ null.\nSet allowed optimizations.\nSet paths of the scanned files.\nSet paths of the scanned files.\nToggle predicate pushdown optimization.\nToggle projection pushdown optimization.\nSet the <code>char</code> used as quote char. The default is <code>b&#39;&quot;&#39;</code>. If …\nRaise an error if CSV is empty (otherwise return an empty …\nRechunk the memory to contiguous chunks when parsing is …\nRechunk the memory to contiguous chunks when parsing is …\nRechunk the memory to contiguous chunks when parsing is …\nTry to estimate the number of rows so that joins can …\nConfigure the row index.\nAdd a new column at index 0 that counts the rows.\nAdd a row index column.\nAdd a row index column.\nSet the CSV file’s schema\nSet the JSON file’s schema\nModify a schema before we run the lazy scanning.\nSet the JSON file’s schema\nSet the CSV file’s column separator as a byte character\nToggle expression simplification optimization on or off.\nSkip the first <code>n</code> lines during parsing. The header will be …\nSkip the first <code>n</code> rows during parsing. The header will be …\nSkip this number of rows after the header location.\nToggle slice pushdown optimization.\nSet sources of the scanned files.\nRun nodes that are capably of doing so on the streaming …\nTruncate lines that are longer than the schema.\nAutomatically try to parse dates/datetimes and time. If …\nToggle type check optimization.\nToggle type coercion optimization.\nTurn off all optimizations.\nOptions for writing CSV files.\nA dynamically inferred literal value. This needs to be …\nNo unique checks\nCheck if join keys are unique in right dataset.\nThe literal Null\nCheck if join keys are unique in left dataset.\nCheck if join keys are unique in both left and right …\nSpecify if the scan provider should allow predicate …\nSpecify if the scan provider should allow projection …\nSpecify if the scan provider should allow slice pushdowns.\nSize of each written chunk.\nCompatibility level\nData page compression\nData page compression\nif <code>None</code> will be 1024^2 bytes\nStart a window at this interval.\nPer-field overwrites for writing properties.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nGetter for the <code>DataType</code> of the value\nAdd the boundaries to the DataFrame.\nTime or index column.\nTime or index column.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nReturns whether the duration consists of full days.\n<code>true</code> if zero duration.\nCustom file-level key value metadata\nTruncate the time column values to the window.\nLiteral expression.\nReturns the nanoseconds from the <code>Duration</code> without the …\nReturns whether duration is negative.\nCreate a new integer size <code>Duration</code>\nProduce the next batch Polars can consume. Implement this …\nOffset window boundaries.\nParse a string into a <code>Duration</code>\nWindow duration.\nWindow duration.\nPrepare the given <code>DslPlan</code> for execution on Polars Cloud.\nIf <code>None</code> will be all written to a single row group.\nCreates a DataFrame from the supplied function &amp; scan …\nfunction to supply the schema. Allows for an optional …\nCompute and write column statistics.")